{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6af6655e-ae65-417c-8189-dd9f69f5acb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings       \n",
    "import pickle\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "import xgboost as xgb\n",
    "from mytools import encontrar_estacao, cortar_serie_temporal, remover_outliers\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2e4f1d-e27c-404e-a96b-5c642c5dcb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dados_A215_H_2008-06-13_2024-01-01.csv',sep= ';', header = 9)\n",
    "df['Data Medicao'] = pd.to_datetime(df['Data Medicao'])\n",
    "df['Hora Medicao'] = pd.to_datetime(df['Hora Medicao'])\n",
    "df['ano'] = df['Data Medicao'].dt.year\n",
    "df['mes'] = df['Data Medicao'].dt.month\n",
    "df['dia'] = df['Data Medicao'].dt.day\n",
    "# df['hora']= df['Hora Medicao'].str[-4:-2].astype(int)\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].str.replace(',', '.').astype(float)\n",
    "\n",
    "\n",
    "df['Hora Medicao'] = df['Hora Medicao'].astype(str)\n",
    "df['hora'] = df['Hora Medicao'].str[-4:-2].astype(int)\n",
    "df = df.drop(['Hora Medicao'],axis=1)\n",
    "df['hora'] = pd.to_timedelta(df['hora'], unit='h') - pd.Timedelta(hours=3)\n",
    "df['Data_Hora'] = df['Data Medicao'] + df['hora']\n",
    "df.set_index('Data_Hora', inplace=True)\n",
    "df['Data_Hora'] = df['Data Medicao'] + df['hora']\n",
    "df = df.drop('Unnamed: 22', axis =1)\n",
    "df['estacao'] = df.apply(encontrar_estacao, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9f6396-b4d1-490f-8167-f138e440f10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "\n",
    "df_crop = cortar_serie_temporal(df = df,data_inicio = '2010-01-01', data_fim = '2020-12-31')\n",
    "\n",
    "df = remover_outliers(df_crop)\n",
    "df.to_csv('cropped.csv')\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "features = ['TEMPERATURA DO PONTO DE ORVALHO(°C)','VENTO, VELOCIDADE HORARIA(m/s)', 'UMIDADE RELATIVA DO AR, HORARIA(%)', 'TEMPERATURA DO AR - BULBO SECO, HORARIA(°C)']\n",
    "target = ['RADIACAO GLOBAL(Kj/m²)']\n",
    "dataframe = df\n",
    "X = dataframe[features].values\n",
    "y = dataframe[target].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9958819f-384b-471e-888d-b13a8ec0d5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR()\n",
    "# Definindo os parâmetros para GridSearchCV\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'epsilon': [0.01, 0.1, 0.5]\n",
    "}\n",
    "\n",
    "# Realizando a busca em grade para encontrar os melhores parâmetros\n",
    "grid_search_svr = GridSearchCV(estimator=svr, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Melhores parâmetros encontrados\n",
    "print(\"Melhores parâmetros para SVR:\", grid_search_svr.best_params_)\n",
    "\n",
    "# Avaliação do modelo\n",
    "svr_best = grid_search_svr.best_estimator_\n",
    "svr_best.fit(X_train_scaled, y_train)\n",
    "svr_pred = svr_best.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "print(\"svr finalizado\")\n",
    "# Definindo o modelo Random Forest\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Definindo os parâmetros para GridSearchCV\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Realizando a busca em grade para encontrar os melhores parâmetros\n",
    "grid_search_rf = GridSearchCV(estimator=rf,\n",
    "                              param_grid=param_grid_rf,\n",
    "                              cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "# Melhores parâmetros encontrados\n",
    "print(\"Melhores parâmetros para Random Forest:\", \n",
    "      grid_search_rf.best_params_)\n",
    "\n",
    "# Avaliação do modelo\n",
    "rf_best = grid_search_rf.best_estimator_\n",
    "rf_best.fit(X_train, y_train)\n",
    "rf_pred = rf_best.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"random florest finalizado\")\n",
    "# Convertendo os dados para DMatrix para uso com XGBoost\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Definindo os parâmetros para XGBoost (exemplo)\n",
    "params = {\n",
    "    'max_depth': 3,\n",
    "    'eta': 0.1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse'\n",
    "}\n",
    "\n",
    "# Treinamento do modelo XGBoost\n",
    "num_round = 100\n",
    "xgb_model = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "# Avaliação do modelo\n",
    "xgb_pred = xgb_model.predict(dtest)\n",
    "\n",
    "# Construindo o modelo de RNA\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1))  # Camada de saída\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
    "\n",
    "# Treinamento do modelo\n",
    "history = model.fit(X_train_scaled, y_train, epochs=50, batch_size=32, validation_data=(X_test_scaled, y_test), verbose=1)\n",
    "\n",
    "# Avaliação do modelo\n",
    "loss = model.evaluate(X_test_scaled, y_test)\n",
    "print(\"Erro de teste (MSE):\", loss)\n",
    "\n",
    "# Previsões\n",
    "rna_pred = model.predict(X_test_scaled).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431058ba-18dc-4d84-8306-a47625be154a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "# Dictionary to store evaluation metrics\n",
    "evaluation_metrics = {}\n",
    "\n",
    "# SVR Evaluation\n",
    "evaluation_metrics['SVR'] = {\n",
    "    'MSE': mean_squared_error(y_test, svr_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, svr_pred)),\n",
    "    'MAE': mean_absolute_error(y_test, svr_pred),\n",
    "    'MAPE': mean_absolute_percentage_error(y_test, svr_pred),\n",
    "    'R²': r2_score(y_test, svr_pred),\n",
    "    'EVS': explained_variance_score(y_test, svr_pred)\n",
    "}\n",
    "\n",
    "# Random Forest Evaluation\n",
    "evaluation_metrics['Random Forest'] = {\n",
    "    'MSE': mean_squared_error(y_test, rf_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, rf_pred)),\n",
    "    'MAE': mean_absolute_error(y_test, rf_pred),\n",
    "    'MAPE': mean_absolute_percentage_error(y_test, rf_pred),\n",
    "    'R²': r2_score(y_test, rf_pred),\n",
    "    'EVS': explained_variance_score(y_test, rf_pred)\n",
    "}\n",
    "\n",
    "# XGBoost Evaluation\n",
    "evaluation_metrics['XGBoost'] = {\n",
    "    'MSE': mean_squared_error(y_test, xgb_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, xgb_pred)),\n",
    "    'MAE': mean_absolute_error(y_test, xgb_pred),\n",
    "    'MAPE': mean_absolute_percentage_error(y_test, xgb_pred),\n",
    "    'R²': r2_score(y_test, xgb_pred),\n",
    "    'EVS': explained_variance_score(y_test, xgb_pred)\n",
    "}\n",
    "\n",
    "# RNA Evaluation\n",
    "evaluation_metrics['RNA'] = {\n",
    "    'MSE': mean_squared_error(y_test, rna_pred),\n",
    "    'RMSE': np.sqrt(mean_squared_error(y_test, rna_pred)),\n",
    "    'MAE': mean_absolute_error(y_test, rna_pred),\n",
    "    'MAPE': mean_absolute_percentage_error(y_test, rna_pred),\n",
    "    'R²': r2_score(y_test, rna_pred),\n",
    "    'EVS': explained_variance_score(y_test, rna_pred)\n",
    "}\n",
    "\n",
    "# Print evaluation metrics for comparison\n",
    "for model_name, metrics in evaluation_metrics.items():\n",
    "    print(f\"{model_name} - MSE: {metrics['MSE']}, \n",
    "    RMSE: {metrics['RMSE']}, MAE: {metrics['MAE']},\n",
    "    MAPE: {metrics['MAPE']}, R²: {metrics['R²']},\n",
    "    EVS: {metrics['EVS']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13c8a1a-4eed-4912-8dcb-099df455bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {'svr_best': svr_best, 'rf_best': rf_best}\n",
    "for name, model in models.items():\n",
    "    with open(f'{name}.pkl', 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "        \n",
    "xgb_model.save_model('xgb_model.json')\n",
    "model.save('rna_model.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
